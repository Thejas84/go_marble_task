# -*- coding: utf-8 -*-
"""gomaeble_assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BtVV96_x6K1fqVU3lvgccuV5YYlo3RR0
"""

!pip install fastapi
!pip install pydantic
!pip install beautifulsoup4
!pip install requests
!pip install nest_asyncio
!pip install pyngrok
!pip install uvicorn
!pip install selenium
!pip install webdriver-manager
!pipinstallopenai
!pip install requests flask flask-ngrok playwright
!playwright install
!playwright install chromium
!pip install nest_asyncio
!pip install flask flask-ngrok playwright openai
!playwright install

import secrets

# Generate a secure token
API_AUTH_TOKEN = secrets.token_urlsafe(32)  # Adjust the length as needed
print(API_AUTH_TOKEN)

!pip install pyngrok
from pyngrok import ngrok

# Importing necessary libraries
!pip install --upgrade openai

from fastapi import FastAPI, HTTPException, Query
from pydantic import BaseModel
from typing import List, Optional
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright
import openai
import uvicorn
import nest_asyncio
from pyngrok import ngrok
import time


# Set your OpenAI API key
openai.api_key = "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"  # Replace with your OpenAI API key
#openai.api_key = "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"

# Initialize FastAPI app
app = FastAPI()

# Set up ngrok authentication (replace with your actual ngrok token)
ngrok.set_auth_token("2rkSl2wfG6CX5L23pt2QGlUXe5N_4TD4LgozLYrjj4dKXNJo2")  # Replace with your actual ngrok token
#ngrok.set_auth_token("ak_2rhYceb2MmUIokdVdnLbx2gaOyk")

# Data models
class Review(BaseModel):
    title: str
    body: str
    rating: Optional[int] = None
    reviewer: Optional[str] = None

class ReviewsResponse(BaseModel):
    reviews_count: int
    reviews: List[Review]
    summarized_reviews: Optional[str] = None

def scrape_reviews_with_playwright(url: str):
    """
    Scrape reviews from any website using Playwright.
    """
    try:
        # Launch Playwright browser
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            page.goto(url, timeout=60000)  # Wait for the page to load

            # Generalized scraping logic
            domain = urlparse(url).netloc
            reviews = []

            if "amazon" in domain:
                reviews = scrape_amazon_reviews_playwright(page)
            elif "flipkart" in domain:
                reviews = scrape_flipkart_reviews_playwright(page)
            else:
                reviews = scrape_generic_reviews_playwright(page)

            browser.close()

            # Summarize reviews if any found
            summarized_reviews = (
                summarize_reviews_with_openai(reviews) if reviews else "No reviews found on this page."
            )
            return ReviewsResponse(reviews_count=len(reviews), reviews=reviews, summarized_reviews=summarized_reviews)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Scraping error: {str(e)}")

def scrape_amazon_reviews_playwright(page):
    """
    Scrape reviews from Amazon using Playwright.
    """
    reviews = []
    try:
        # Scroll and wait for reviews to load
        page.wait_for_selector(".review", timeout=15000)
        page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(5)  # Allow more reviews to load

        # Extract reviews
        review_elements = page.query_selector_all(".review")
        for element in review_elements:
            title = element.query_selector(".review-title").inner_text() if element.query_selector(".review-title") else "No title"
            body = element.query_selector(".review-text-content").inner_text() if element.query_selector(".review-text-content") else "No content"
            rating_text = element.query_selector(".review-rating").inner_text() if element.query_selector(".review-rating") else None
            rating = int(rating_text.split()[0]) if rating_text and rating_text[0].isdigit() else None
            reviewer = element.query_selector(".a-profile-name").inner_text() if element.query_selector(".a-profile-name") else "Anonymous"
            reviews.append(Review(title=title, body=body, rating=rating, reviewer=reviewer))

    except Exception as e:
        print(f"Error scraping Amazon reviews: {str(e)}")
    return reviews

def scrape_flipkart_reviews_playwright(page):
    """
    Scrape reviews from Flipkart using Playwright.
    """
    reviews = []
    try:
        page.wait_for_selector("._1AtVbE", timeout=15000)
        review_elements = page.query_selector_all("._1AtVbE")

        for element in review_elements:
            title = element.query_selector(".row .col .review-title").inner_text() if element.query_selector(".review-title") else "No title"
            body = element.query_selector("._2-N8zT").inner_text() if element.query_selector("._2-N8zT") else "No content"
            rating_text = element.query_selector("._3LWZlK").inner_text() if element.query_selector("._3LWZlK") else None
            rating = int(rating_text) if rating_text and rating_text.isdigit() else None
            reviewer = element.query_selector(".row .col .review-author").inner_text() if element.query_selector(".review-author") else "Anonymous"
            reviews.append(Review(title=title, body=body, rating=rating, reviewer=reviewer))

    except Exception as e:
        print(f"Error scraping Flipkart reviews: {str(e)}")
    return reviews

def scrape_generic_reviews_playwright(page):
    """
    Enhanced scraper for generic reviews using Playwright with debugging.
    """
    reviews = []
    try:
        # Wait for the page to load
        page.wait_for_selector("body", timeout=20000)

        # Scroll to ensure dynamic content loads
        page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(10)  # Wait for content to load

        # Debug: Save a screenshot to verify the page
        page.screenshot(path="page_debug.png", full_page=True)

        # Find all potential review-related elements
        elements = page.query_selector_all("p, div")
        for element in elements:
            text = element.inner_text()
            if "review" in text.lower():
                reviews.append(Review(title="No title", body=text, rating=None, reviewer=None))

        # Debug: Log the number of reviews found
        print(f"Found {len(reviews)} potential reviews.")

    except Exception as e:
        print(f"Error scraping generic reviews: {str(e)}")
    return reviews


def summarize_reviews_with_openai(reviews: List[Review]) -> str:
    """
    Summarize reviews using OpenAI's ChatCompletion API.
    """
    try:
        # Combine all reviews into a single input
        reviews_text = "\n".join([f"Title: {review.title}\nRating: {review.rating}\nReview: {review.body}" for review in reviews])

        # Call OpenAI's ChatCompletion API
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # Use "gpt-4" if you have access
            messages=[
                {"role": "system", "content": "You are an assistant that summarizes product reviews."},
                {"role": "user", "content": f"Summarize the following product reviews:\n\n{reviews_text}"}
            ],
            max_tokens=150,
            temperature=0.5
        )

        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        return f"Error summarizing reviews: {str(e)}"

# API endpoint
@app.get("/api/reviews", response_model=ReviewsResponse)
def get_reviews(url: str = Query(..., description="Product URL")):
    return scrape_reviews_with_playwright(url)

# Run FastAPI app with ngrok
nest_asyncio.apply()
public_url = ngrok.connect(8000)
print(f"FastAPI app is available at: {public_url}")

# Run FastAPI app
uvicorn.run(app, host="0.0.0.0", port=8000)